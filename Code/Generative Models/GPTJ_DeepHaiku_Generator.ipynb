{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Haiku Generator**\n",
        "### Generating Haikus after finetuning a large transformer withÂ structures poems, their phonemes and using topics.\n",
        "\n",
        "Fine tuning the model needs enough compute resources  Training - hence using the Tuned model\n",
        "\n",
        "\n",
        "## Acknowledgements\n",
        "\n",
        "@software{DeepHaiku,\n",
        "  author  = {Gonsalves, Robert A.},\n",
        "  title   = {Deep Haiku: Teaching GPT-J to Compose with Syllable Patterns},\n",
        "  url     = {https://github.com/robgon-art/DeepHaiku},\n",
        "  year    = 2022,\n",
        "  month   = February\n",
        "}"
      ],
      "metadata": {
        "id": "TOiwBqJpL0Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation and Setup"
      ],
      "metadata": {
        "id": "zB2fNlPSNxel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "## !git clone https://github.com/unitaryai/detoxify\n",
        "# !pip install transformers==4.16.2\n",
        "# !pip install bitsandbytes-cuda111\n",
        "## !git clone https://github.com/robgon-art/GRUEN\n",
        "# !pip install wmd\n",
        "# !pip install --upgrade --no-cache-dir gdown\n",
        "# !gdown --id 1S-l0L_YOzn5KhYHdB8iS37qKwuUhHP0G\n",
        "# !gdown --id 10LpkO5Vm_zOu723FVk6cCeRsv_qyYLdL\n",
        "# !unzip cola_model.zip\n",
        "# !pip install phonemizer\n",
        "# !sudo apt-get install festival\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "from tqdm.auto import tqdm\n",
        "from phonemizer import phonemize\n",
        "from phonemizer.separator import Separator\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jPU9dV2I6nJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required Classes and Functions "
      ],
      "metadata": {
        "id": "YWIlY0MFSFUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_festival_phonemes(line):\n",
        "  phn = phonemize(line, language='en-us', backend='festival', with_stress=False,\n",
        "      separator=Separator(phone=None, word=' ', syllable=\"|\"), strip=True)\n",
        "  return phn\n",
        "\n",
        "text = [\"pet pug arthur\"]\n",
        "get_festival_phonemes(text)"
      ],
      "metadata": {
        "id": "xRZAIkuQSFC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        " \n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output\n",
        " \n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        " \n",
        " \n",
        "class DequantizeAndLinear(torch.autograd.Function): \n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias)\n",
        " \n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        " \n",
        " \n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        " \n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        if self.adapter:\n",
        "            output += self.adapter(input)\n",
        "        return output \n",
        " \n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        " \n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        " \n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        " \n",
        " \n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr( \n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "        \n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "print(\"Init Done!\")"
      ],
      "metadata": {
        "id": "0YODeo4zSAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model "
      ],
      "metadata": {
        "id": "FLyFKlxrSio_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J\n",
        "\n",
        "import transformers\n",
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "\n",
        "gpt = torch.load(\"/content/gpt-j-8bit_deep_haikul.pt\",  map_location=torch.device('cuda'))\n",
        "gpt.eval()"
      ],
      "metadata": {
        "id": "xVBcqu88SjyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Function\n",
        "Input Topic to Generate poems "
      ],
      "metadata": {
        "id": "ihranMqMQiet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "_qW2u4n2SmbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(topic:str ='nature',max_length=40,num_poems = 50):\n",
        "  '''\n",
        "  Generator for Haikus - strcutred poems \n",
        "\n",
        "  Inputs:\n",
        "    topic: Any string type topic\n",
        "    max_length: max length of the poem\n",
        "    num_poems: total number of poems to be generated\n",
        "  Output:\n",
        "    A pandas Dataframe with sent_1,sent_2,sent_3 as columns representing 3 lines of poem\n",
        "  '''\n",
        "  \n",
        "  input = \"(\" + topic.strip()\n",
        "  if not \"=\" in topic:\n",
        "    input += \" =\"\n",
        "    print(\"'\" + input + \"'\")\n",
        "  with torch.no_grad():\n",
        "    input_tokens = tokenizer(input, return_tensors=\"pt\").input_ids.cuda()\n",
        "    sample_outputs = gpt.generate(input_tokens, max_length=max_length, do_sample=True, num_return_sequences=num_poems, temperature=0.8)\n",
        "      \n",
        "  haikus = []\n",
        "\n",
        "  for i, sample_output in enumerate(sample_outputs):\n",
        "    doc = (tokenizer.decode(sample_outputs[i], skip_special_tokens=True))\n",
        "    haiku = doc.split(\")\")[0][1:].strip().split(\" = \")[1].strip()\n",
        "    haikus.append(haiku)\n",
        "\n",
        "  print(\"Deep Haiku Generation for \" + topic.upper() + \" #Haikus generated: \" + str(len(haikus)))\n",
        "  haikus = pd.Series(haikus).str.replace(\". / \", \" / \")\n",
        "  temp = haikus.str.split('/',expand=True)\n",
        "  if len(temp.columns)>3:\n",
        "    for i in range(3,len(temp.columns)):\n",
        "      d = list(np.where(pd.isna(temp[i])==False)[0])\n",
        "      temp = temp.drop(d,axis=0)\n",
        "  temp = temp[[0,1,2]].copy()\n",
        "  temp.columns = ['sent_1','sent_2','sent_3']\n",
        "\n",
        "  '''Takes time'''\n",
        "  # temp['toxicity'] = list(haikus.apply(lambda h: Detoxify('original').predict(h)[\"toxicity\"]))\n",
        "  return temp\n"
      ],
      "metadata": {
        "id": "Ro3wmWhQF_Re"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = generator() #default topic: nature\n",
        "final = temp \n",
        "topics = ['autumn','machine learning', 'AI','spring','butterflies']\n",
        "for t in topics:\n",
        "  print(t)\n",
        "  final = pd.concat([final,generator(t)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBMd9jmiLbBN",
        "outputId": "fba06508-f7ff-4ff5-8332-4084c05b3419"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'(nature ='\n",
            "Deep Haiku Generation for NATURE #Haikus generated: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p14h3J2ER1v5",
        "outputId": "88fbe3a7-f52e-4bf1-9b65-5d1b2bd1e040"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    sent_1                           sent_2  \\\n",
              "0       Oh, the beauty of      Unrestrained nature, please    \n",
              "1    Live your purpose in          Balance with the nature    \n",
              "2       The natural world       No longer bothers to decor    \n",
              "3       The nature of man       Can't explain how I became    \n",
              "4  Take me back to nature    Take me back to the mountains    \n",
              "\n",
              "                    sent_3  \n",
              "0    Stay out of my house.  \n",
              "1           Spirit nature.  \n",
              "2   Dress up for the cams.  \n",
              "3           What I am now.  \n",
              "4    Take me back to pain.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28f8778c-d1bf-40c1-930a-2330e2248c44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_1</th>\n",
              "      <th>sent_2</th>\n",
              "      <th>sent_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh, the beauty of</td>\n",
              "      <td>Unrestrained nature, please</td>\n",
              "      <td>Stay out of my house.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Live your purpose in</td>\n",
              "      <td>Balance with the nature</td>\n",
              "      <td>Spirit nature.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The natural world</td>\n",
              "      <td>No longer bothers to decor</td>\n",
              "      <td>Dress up for the cams.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The nature of man</td>\n",
              "      <td>Can't explain how I became</td>\n",
              "      <td>What I am now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Take me back to nature</td>\n",
              "      <td>Take me back to the mountains</td>\n",
              "      <td>Take me back to pain.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28f8778c-d1bf-40c1-930a-2330e2248c44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28f8778c-d1bf-40c1-930a-2330e2248c44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28f8778c-d1bf-40c1-930a-2330e2248c44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv('deep_haiku_op.csv',index=False)"
      ],
      "metadata": {
        "id": "NtyU0UGAJw7p"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtnjpOIkJ02r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}